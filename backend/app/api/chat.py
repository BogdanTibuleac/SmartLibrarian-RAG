from fastapi import APIRouter, Body
from app.rag.chroma_setup import collection
from app.rag.embeddings import get_embedding
from app.tools.moderation import is_prompt_flagged
from app.tools.distance import normalize_distances
import openai
import os
from dotenv import load_dotenv

MAX_ACCEPTABLE_RAW_DISTANCE = 1.19  # or adjust as needed

router = APIRouter()
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def log_valid_results(results):
    print("\nğŸ“Š Top Matches:")
    for i, (doc, meta, raw_dist, norm_dist) in enumerate(results):
        print(f"ğŸ“š #{i+1}: {meta.get('title', 'N/A')}")
        print(f"ğŸ“ Raw distance: {raw_dist:.4f} | Normalized: {norm_dist:.4f}")
        print(f"ğŸ“ Summary (trimmed): {doc[:100]}...\n")


@router.post("/")
def get_book_recommendation(query: str = Body(..., embed=True)):
    if not query or len(query.strip()) < 3:
        return {"error": "Interogare prea scurtÄƒ. Te rog reformuleazÄƒ."}

    if is_prompt_flagged(query):
        return {
            "recommended_title": None,
            "explanation": "Te rog formuleazÄƒ Ã®ntrebarea Ã®ntr-un mod respectuos. ÃÈ›i stau la dispoziÈ›ie cu recomandÄƒri literare.",
            "source_summary": None
        }

    print(f"ğŸ” Query: {query}")
    query_embedding = get_embedding(query)

    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=3,
        include=["documents", "metadatas", "distances"]
    )

    documents = results["documents"][0]
    metadatas = results["metadatas"][0]
    distances = results["distances"][0]
    normalized_distances = normalize_distances(distances)

    valid_results = []
    for i, (doc, meta, raw_dist, norm_dist) in enumerate(zip(documents, metadatas, distances, normalized_distances)):
        if doc and meta:
            valid_results.append((doc, meta, raw_dist, norm_dist))

    if not valid_results:
        return {
            "recommended_title": None,
            "explanation": "Ãmi pare rÄƒu, dar nu am gÄƒsit nicio carte potrivitÄƒ Ã®n baza de date curentÄƒ.",
            "source_summary": None
        }

    # ğŸ§¾ Log top 3 results in console (for developer visibility)
    log_valid_results(valid_results)

    # âœ… Use only the top result for the GPT explanation
    top_doc, top_meta, raw_dist, norm_dist = valid_results[0]
    
    
    if raw_dist > MAX_ACCEPTABLE_RAW_DISTANCE:
        print(f"âš ï¸ Top result too far (raw distance: {raw_dist:.4f}) â€” skipping GPT.")
        return {
            "recommended_title": None,
            "explanation": "Ãmi pare rÄƒu, dar nu am gÄƒsit nicio carte relevantÄƒ pentru Ã®ntrebarea ta.",
            "source_summary": None,
            "normalized_distance": norm_dist
    }

    prompt = f"""
ÈšinÃ¢nd cont de interogarea: "{query}", oferÄƒ o recomandare pe baza urmÄƒtoarei cÄƒrÈ›i, care este cea mai apropiatÄƒ semantic dintre toate cele din baza de date (scor: {norm_dist:.4f}).

Titlu: {top_meta.get("title", "N/A")}
Rezumat: {top_doc.strip()}

Scrie o recomandare prietenoasÄƒ, clarÄƒ È™i scurtÄƒ. ExplicÄƒ de ce aceastÄƒ carte rÄƒspunde cerinÈ›ei utilizatorului, fÄƒrÄƒ a inventa alte opÈ›iuni.
"""

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    gpt_reply = response['choices'][0]['message']['content'].strip()

    print("ğŸ§  GPT Explanation:\n", gpt_reply)

    return {
        "recommended_title": top_meta.get("title"),
        "explanation": gpt_reply,
        "source_summary": top_doc,
        "normalized_distance": norm_dist
    }
   